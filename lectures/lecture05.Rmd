---
title: "Stats 306: Lecture 5"
subtitle: "Tables: Selecting, Filtering; Grouping and Summaries"
author: "Mark Fredrickson"
output: 
  learnr::tutorial:
    progressive: true
    css: css/lecture.css
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
library(lubridate) # install.packages("lubridate") if you don't have this
```


## Tables: lists of vecotrs

Review:

* Samples: collections of $n$ units
* Variables: $k$ measurements common to all units
* Tables ($n \times k$): units on rows, variables on columns
* Conceptual table implementation: lists of length $k$ composed of vectors of length $n$

Example:
```{r}
x <- 1:10
y <- 100:109
length(x)
length(y)
d <- list(column_x = x, column_y = y)
d
d$column_x
```

## Better tables: `data.frame` and `tibble`

A list of vectors could not guarantee they are all the same length. Instead we use **`data.frame`** and **`tibble`**.

```{r}
d2 <- as.data.frame(d)
dim(d2)
d3 <- as_tibble(d2)
d3
```

## Common operations on tables (overview)

* Pulling out a single column: `d$col`
* Creating a single column: `d$newcol <- EXPR`
* Pulling out several columns: `select(d, col1, col2)` (and several other forms)
* Pulling out rows: `filter(d, criterion1, criterion2)`
* Creating new columns (in new table): `mutate(d, newcol = f(col1, col2), newcol2 = g(col3, newcol))`
* Grouping and summarizing `group_by(d, discrete_column) |> summarize(new_name = f(col))`

## Getting and setting columns (one at a time)

Recall: to get something out of a list, use the dollar sign `$` operator

```{r}
d3$column_x
d3$x_plus_y <- d3$column_x + d3$column_y
head(d3, 2)
```

## Getting several columns at once

```{r}
select(d3, column_x, x_plus_y) |> head(2)
```

## Getting all but some columns

```{r}
select(d3, !column_x) |> head(2)
```

## Selectively grabbing columns

```{r}
d3$letter <- letters[d3$column_x]
d3$LETTER <- LETTERS[27 - d3$column_x]
head(d3, 2)
```
Get only "character" type columns:
```{r}
select(d3, where(is.character)) |> head(2)
```

## 'is' functions for columns

* `is.character`: strings/character vectors
* `is.numeric`: number/numeric
* `is.factor`: factor/categories
* `is.logical`: logical/boolean
* `is.double`, `is.integer`: decimal and integer numeric types, respectively

When we start to write our own functions, we'll be able to create many more

## Grabbing rows by index

Tables in R allow for **two-dimensional indexing**: `tbl[rows, cols]`.

```{r}
d3[1, ]
d3[2:4, ]
d3[, c("column_x", "LETTER")]
d3[1:3, c("letter", "LETTER")]
```

## Grabbing rows by criteria (old school)

```{r}
d3[d3$column_y > 105, ]
```

## Grabbing rows (new school)

```{r}
filter(d3, column_y > 105)
```

## Multiple criteria

```{r}
filter(d3, column_y > 105 & column_x < 9)
```

```{r}
filter(d3, column_y > 108 | column_x  < 3)
```

## Exercise

Combine `filter` and `select` to get only the columns `cty` and `hwy` for cars that have more than 4 cylinders.

```{r}
head(mpg, 1)
```

```{r filter-select, exercise = TRUE}

```

## Tasks
* Creating new column (in new table): `mutate(d, newcol = f(col1, col2))`
* Grouping and summarizing `group_by(d, discrete_column) |> summarize(new_name = a_function(col))`

## Mutate: create columns

Before we had code like:
```{r eval = FALSE}
df$new_column <- f(df$x, df$y)
```

It would be convenient to avoid the repeated `df$`:
```{r eval = FALSE}
new_df <- mutate(df, new_column = f(x, y))
```

## Mutate creates new tables

```{r}
dim(aatemp)
aatemp2 <- mutate(aatemp, tdiff = c(NA, diff(TMAX)))
dim(aatemp)
dim(aatemp2)
```

## Mutate for multiple columns

```{r}
aatemp3 <- mutate(aatemp,
                  tdiff = c(NA, diff(TMAX)),
                  tdiff_abs = abs(tdiff))
```

## Mutate to remove columns

```{r}
# NB: reassigning to same variable name
aatemp3 <- mutate(aatemp3, tdiff = NULL)
colnames(aatemp3)
```

## Using helper functions

Recall a $Z$-score is defined by:
$$Z = \frac{X - \bar X}{\hat \sigma}$$

```{r}
aatemp3 <- filter(aatemp3, !is.na(tdiff_abs))
aatemp3 <- mutate(aatemp3, z = (tdiff_abs - mean(tdiff_abs)) / sd(tdiff_abs))
ggplot(aatemp3, aes(x = z)) + geom_histogram()
```

## Conditional evaluation with `if_else`

We may want to create new values using a condition. The `if_else` and function can help:
```{r}
if_else(c(TRUE, FALSE, FALSE), c("aT", "bT", "cT"), c("aF", "bF", "cF"))
```

R will also "recycle" values, so we can pass in single value that will get repeated:
```{r}
x <- c(-2, 1.4, -0.25, 7)
if_else(x < 0, 0, x)
```

There is also `ifelse`, which is similar, but a bit more permissive in what it allows for the two result vectors.

## Exercise

We often want to express variables on a different scale, such as constraining them to be between 0 and 1:
$$Y_i = \frac{X_i - \min(X)}{ \max(X) - \min(X)}$$

Use `mutate` to rescale `x` in this data: 
```{r rescale, exercise= TRUE}
d <- data.frame(x = rnorm(10))

```

## Exercise

Use `if_else` to replace any value greater than 1 with the value 1 and any value less than -1 with the value -1 (this is called "top coding").(*Hint*: you may want to do it two steps.)

```{r topcoding, exercise = TRUE}
d <- data.frame(x = c(-0.19, 1.35, 1.21, -0.11, -0.99, 
                      -0.4, -0.04, -0.4, 0.82, -1.55))

```

## `transmute`: `mutate` + `select`

If you only want the new column(s), you can use `transmute`:

```{r}
transmute(aatemp, degrees_from_freezing = abs(TMAX - 32)) |> summary()
```

## `summary` and `summarize`

R has a built in a function called `summary` that gives a distilled look at a table:
```{r}
aat_4col <- select(aatemp, c("STATION", "DATE", "TMAX", "SNOW"))
summary(aat_4col)
```

The `summarize` function is from `dplyr` (part of `tidyverse`) and allows computing arbitrary summaries.

```{r}
summarize(aat_4col, avg_TMAX = mean(TMAX), days_of_snow = sum(!is.na(SNOW)))
```

## Summarize variations: `_if`, `_at`, `_all`

```{r}
select(aatemp, where(is.numeric)) |> summarize_all(mean, na.rm = TRUE)
summarize_if(aatemp, is.numeric, var, na.rm = TRUE)
summarize_at(aatemp, c("TMAX", "TMIN"), c(maximum = max, minimum = min))
```

## Exercise

For the `mpg` data set, compute the mean `hwy` mileage and median `cty` mileage. Compute the variance of the ratio of `hwy` to `city`.
```{r summary, exercise = TRUE}

```

## Grouping

Often we want to break data out across categories and compute summaries within each.

```{r}
group_by(aatemp, year(DATE)) |> summarize(avg_TMAX = mean(TMAX), days_of_snow = sum(!is.na(SNOW)))
```

## Inspecting group data

```{r}

aat_year <- group_by(aatemp, year(DATE))
nrow(aat_year) == nrow(aatemp)
colnames(aat_year)[18]
group_vars(aat_year)
```

## Grouping by year and month
```{r}
aat_year_month <- group_by(aat_year, month(DATE), .add = TRUE)
group_vars(aat_year_month)
```

```{r}
aat_year_month <- group_by(aatemp, year(DATE), month(DATE))
group_vars(aat_year_month)
```

## Aggregating up with `summarize`

```{r}
summarize(aat_year_month, avg_TMAX = mean(TMAX)) |>
  ggplot(aes(x = `year(DATE)` + `month(DATE)` / 12, avg_TMAX)) +
  geom_line()

```

## Aggregating up two levels

```{r}
summarize(aat_year_month, monthly_avg_tmax = mean(TMAX)) |>
  summarize(yearly_median_monthy_mean = median(monthly_avg_tmax))
```

## Exercise

Using the `mpg` data set, find the manufacturer (`manufacturer`) with the highest mean highway efficiency (`hwy`)
```{r manufacturer-hwy, exercise = TRUE}

```

## Arranging output

Sometimes we want to choose the ordering of rows in a table. I don't use this a lot for raw data, but it can be quite helpful for summaries:

```{r}
group_by(aatemp, year(DATE)) |> 
  summarize(yearly_maxT = max(TMAX)) |> 
  arrange(yearly_maxT)
```

## Descending order, multiple columns


```{r}
group_by(aatemp, year(DATE)) |> 
  summarize(yearly_maxT = max(TMAX), yearly_minT = min(TMAX)) |> 
  arrange(desc(yearly_maxT), yearly_minT)
```

## Exercise

Group by both `manufacturer` and `class`. What manufacturer has the highest `cty` efficiency in the sense of the median of mean `cty` within class?

```{r manufacturer-hwy, exercise = TRUE}
```


