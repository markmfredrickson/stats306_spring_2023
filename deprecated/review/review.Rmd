---
title: "Stats 306: Final Review Session"
author: "Stats 306 GSIs"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

## Set up

```{r installPackages, echo=FALSE, include=FALSE, message=FALSE}
# This just checks if students need to install some packages that they might 
# not have.
if (!require(ggbeeswarm))
  install.packages("ggbeeswarm", repos = "http://cran.us.r-project.org")
```

```{r setup, eval=TRUE, include=TRUE, message=FALSE, echo=TRUE}
library(learnr)     # For interactive exercises
library(tidyverse)
library(parallel)
library(bench)
library(nycflights13)
```

```{r tutorialOptions, include=FALSE, message=FALSE, echo=FALSE}
tutorial_options(exercise.reveal_solution=FALSE)
```

## Logistics

- Exam details: TODO.
- Today's outline: One hour of review, followed by one hour of time for questions.

## Lab 1 (Jesse / Yilei)

### Basic `git` Concepts

* **repository**: A representation of the current state of a collection of files, along with its entire history of modifications. 
* **commit** (noun): A recorded change made to the repository. 
* **branch**: While we won't do a lot with branches in this course, they are a very useful way of collaborating. Branches are essentially additional versions of the repository that you can create, name, delete, and merge into the main (or master) branch of the repository. 

### ggplot2

Every ggplot2 plot has three key components:

- data

- A set of aesthetic mappings between variables in the data and visual properties, and

- At least one layer which describes how to render each observation. Layers are usually created with a geom function.

(Source: https://ggplot2-book.org/getting-started.html)

ggplot is a layer-based function. We first create a coordinate system that you can add layers to using the function ggplot(data=...). This will creates an empty graph.

```{r step1}
ggplot(data = diamonds)
```

We then add the data points onto this empty graph using the function `geom_point()`. The argument `mapping = aes(x = carat, y = price)` tells R what variables (columns in diamonds) we want to plot on each axis.

```{r step2}
ggplot(data = diamonds) + 
    geom_point(mapping = aes(x = carat, y = price))
```

It would be helpful to also visualize the color of diamonds in the scatter plot. We can study this more in depth by making a third variable and map to some aesthetic (i.e., visual property) of the points. Some examples are color, shape, size, and transparency.

```{r step3}
ggplot(data = diamonds) + 
    # carat on x-axis, price on y-axis, color represents different colors of the diamonds
    # alpha is the transparency of the points
    geom_point(mapping = aes(x = carat, y = price, color = color), alpha=0.7)
```

Then we can use labs and ggtitle to specify axis labels and the title.

```{r step4}
ggplot(data = diamonds) + 
    geom_point(mapping = aes(x = carat, y = price, color = color), alpha=0.7) +
    # specify axis labels
    labs(x = 'Carats', y = 'Price($)') + 

    # specify the title
    ggtitle('Diamond price by carat count')
```

You can get a better background by changing the theme. You can find more information about ggplot [here](https://ggplot2.tidyverse.org/reference/ggtheme.html).

```{r step5}
ggplot(data = diamonds) + 
    geom_point(mapping = aes(x = carat, y = price, color = color), alpha=0.7) +
    # specify axis labels
    labs(x = 'Carats', y = 'Price($)') + 

    # specify the title
    ggtitle('Diamond price by carat count') +
  theme_bw()
```

You can also create subplots for different cut types by using `facet_wrap()`:

```{r facet}
ggplot(data = diamonds) + 
    geom_point(mapping = aes(x = carat, y = price, color = color), alpha=0.7) +
    facet_wrap(~cut, ncol=3) +
    labs(x = 'Carats', y = 'Price($)') + 
    ggtitle('Diamond price by carat count') +
  theme_bw()
```

## Lab 2 (Victor)

### Plotting with `ggplot2`

A plot made using `ggplot2` has several components:

* The graph object itself (created using `ggplot()`)
* A set of *aesthetic* mappings connecting variables to visual properties
* Layers: collections of geometric elements (`geom_*()`) and statistical transformations (`stat_*()`)
* Scales: information on the range or composition of variables
* Coordinate systems: how the data are arranged spatially
* Facet: breaking a single plot into several similar plots for different subgroups
* Theme: all the other color and printing aspects of the plot

### Aesthetics and Aesthetic Mappings

An *aesthetic* is a visual property of the geometric elements in a plot.

```{r aesthetic_mappings_example}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = cty, y = hwy, color = drv))
```

Geometric elements represent observations in the dataset. In the plot above, the points are the geometric elements. Different geometric elements have different aesthetics. Some aesthetics of points are

* `x`, or x-coordinate
* `y`, or y-coordinate
* `color`
* `shape`
* `size`

An *aesthetic mapping* is an assignment of an aesthetic to a variable in the dataset. Aesthetic mappings are listed inside `aes()`. For example, in the previous plot, the aesthetic `x` was mapped to the variable `cty`.

### Geometric Elements (Geoms)

A *geometric element* or *geom* is a geometric object that is used in a plot to represent observations. A geom can represent

  * one observation;
  * a group of observations;
  * all of the observations.

A `ggplot2` plot consists of a base created by `ggplot()` and zero or more layers, each representing observations in a particular dataset using a particular geom.

### Statistical Transformations (Stats)

A *statistical transformation* or *stat* is an algorithm that computes from raw data values the values that will be plotted. The available stats are implemented in functions whose names begin with `stat_`. A stat is applied even when the raw values themselves are to be plotted. In that case, the stat that is applied is `stat_identity()`.

The dataset `diamonds` doesn't contain the minimum, median, and maximum for each cut:
```{r stat_summary_example2}
head(diamonds)
```

However, we can use `stat_summary()` to plot those summary statistics:
```{r stat_summary_example1}
ggplot(data = diamonds) + 
  stat_summary(
    mapping = aes(x = cut, y = depth),
    fun.min = min,
    fun.max = max,
    fun = median
  )
```

## Lab 3 (Jesse)

### `ggplot2` facets

One way to plot categorical variables is using *facets*. 
Facets allow us to create separate figures based on some categorical variable, and each resulting figure shares many of the same properties (this is sometimes called the *small multiples* rule in visualization). 

Example: 

```{r ggplot2Facet}
ggplot(data = mpg, aes(x = displ, y = hwy)) + 
  geom_point() + 
  geom_smooth() + 
  facet_wrap(~drv)
```

Every `ggplot` object has a facet, and there are three types: 

* `facet_wrap`: Creates a one-dimensional set of plots, that are often shown in a 2d grid.
* `facet_grid`: Creates a two-dimensional grid of panels, defined by two different columns. 
* `facet_null`: This is the default facet, which is just a single plot

### `ggplot2` coordinate systems

Like facets, every `ggplot2` object has a coordinate system. 
There are many different types of coordinate systems in `ggplot2`. 

There are *linear* coordinate systems that don't change the shape of `geoms`: 

- `coord_cartesian()`: Default coordinate system
- `coord_flip()`: Default coordinate system, but flipping `x` and `y` axis. 
- `coord_fixed()`: Default coordinate system, but fixing the ratio between `x` and `y` axis. 

There are also *non-linear* coordinate systems, that can change the shape of `geoms`: 

- `coord_polar()`: Polar coordinates.
- `coord_map()`: Map projections (spherical earth to 2D plane).
- `coord_trans()`: Custom transformations to `x` and `y` positions. 

Polar coordinate example: 

```{r mtcarsPolar}
my_cars <- mtcars
my_cars$model <- rownames(mtcars)
ggplot(my_cars) + 
  geom_bar(aes(y = mpg, x = model), stat = 'identity') + 
  coord_polar() + 
  theme_bw()
```

We may be interested in Polar Coordinates if we are visualizing data that might have seasonal/cyclical effects.
For example, if we plot temperatures by month in a standard coordinate system, January and December are on opposite sides of the figure, despite having similar values and are actually close in time. 
In a Polar Coordinates plot of the same monthly temperature data, January and December will be right next to eachother. 

## Lab 4 (Yilei)

### Mutate Function

`mutate()` function is used to create new columns in a dataset.

```{r}
iris1 <- mutate(iris, ID = row_number(),
                Species.Upper = toupper(Species),
                previous = lag(Sepal.Length),
                iris, Size = case_when(
                 Sepal.Length < mean(Sepal.Length) ~ "small",
                 Sepal.Length > mean(Sepal.Length) ~ "large",
                   TRUE ~ "medium"))
head(iris1)

```

We can use informative titles to help us mutate the columns we need:

```{r}
iris1 <- mutate(iris, across(starts_with("Sepal"), ~ . / 10)) 
head(iris1)
```

Breaking down the syntax above:

* across: specifies a set of columns to mutate
* ~ indicates the start of a formula to apply across several columns
* . dummy variable standing in for each column


### Rename function

We use rename to rename existing column names. Dots(`.`) are not recommended for variable names, we want to rename all columns names in the iris dataset by replacing `.` with `_`.

```{r}
iris2 <- rename(iris, Sepal_Length = Sepal.Length,
                      Sepal_Width = Sepal.Width,
                      Petal_Length = Petal.Length,
                      Petal_Width = Petal.Width)

iris3 <- rename_with(iris, ~ str_replace(., pattern="\\.", replacement = "_"))
head(iris2)
names(iris2)
names(iris3)
```

* We can use rename_with() to apply a (string) function to all columns by default or a specific subset.

### group_by() and summarise()

We can first group the dataset by a variable, and then make some operations within each group:

```{r}
by_group <- group_by(iris, Species)

summarise(by_group, mean_sep_length = mean(Sepal.Length),
          mean_sep_width = mean(Sepal.Width))
```

### Pipe Operator

We can use the pipe sign `%>%` to connect several implementations, to make the codes clear and reduce intermediate steps. For example:

```{r}
iris %>%                                                ## then
    filter(Petal.Length > 1 & Sepal.Width < 3.3) %>%    ## and then
    select(Sepal.Length, Sepal.Width, Species) %>%      ## and then
    rename(sepal_length = Sepal.Length,
           sepal_width = Sepal.Width,) %>%              ## and then
    mutate(Species = toupper(Species)) %>%              ## and then
    group_by(Species) %>%                               ## and then
    summarise(mean_sep_length = mean(sepal_length),
              mean_sep_width = mean(sepal_width),
              `50th_tile_sep_len` = quantile(sepal_length, 0.5),
              `50th_tile_sep_width` = quantile(sepal_width, 0.5)
              )

```


## Lab 5 (Benjamin)

## Lab 6 (Victor)

### Exploratory Data Analysis

**Exploratory data analysis (EDA)** can be thought of as a cycle:

- Generate questions about your data.
- Search for answers by visualizing, transforming, and modelling your data.
- Use what you learn to refine your questions and/or generate new questions.

### Variation

**Variation** refers to a variable's tendency to change in value from measurement to measurement.

How variation is visualized depends on the type of the variable

- Continuous variables
  - Can take any value in an infinite set of ordered values
  - Typically visualized using histograms and boxplots
- Categorical variables
  - Can take any value in a finite set of categories/levels
  - Typically visualized using barplots
- Aspects of variation frequently focused on:
  - Typical/atypical values
  - Unusual values
  - Missing values

`storms` has data on tropical storms. Each row has measurements on a particular storm made at a particular time.

```{r}
head(storms)
```

The most common category is 0; the next most common is -1. From weather reports, you might expect 1-5 to be the only categories. The documentation on `storms` says that -1 represents a tropical depression and 0 represents a tropical storm. Also, going from 0 to 5, the count declines, which makes sense, since the higher the category, the higher the severity.

```{r}
storms %>% ggplot() + geom_bar(aes(category))
```

### Covariation

**Covariation** refers to how the value of one variable changes as the value of another variable changes. How to visualize covariation depends on the types of the two variables.

- One Categorical Variable, One Continuous Variable
- Two Categorical Variables
- Two Continuous Variables

#### One Categorical Variable, One Continuous Variable

- `geom_freqpoly()` plots one line for each level of a categorical variable
- The height of a line over a value of the continuous variable reflects the frequency of that value
- Not that useful when there are many levels - the plot gets too cluttered

The plot below shows the `price` frequency for each quality (`cut`) level for the `diamonds` dataset. The frequencies are quite different for different quality levels, making it hard to see the pattern for the quality level at the bottom.
```{r}
ggplot(data = diamonds, mapping = aes(x = price)) + 
  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500) +
  theme_bw()
```

Plotting densities instead of frequencies can help in a situation like this:
```{r}
ggplot(data = diamonds, mapping = aes(x = price, y = after_stat(density))) + 
  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500) +
  theme_bw()
```

#### Two Continuous Variables

- `geom_point()` can make it easy to see relationships.
- However, the more data you have, the harder it can be to see the trend. There are several ways to address this problem:
  - Changing the point transparency (`alpha`)
  - Binning
  - Discretizing

The plot below shows the relationship between carat and price. Since there are tens of thousands of points, overplotting may be a problem.
```{r}
ggplot(data = diamonds) +
  geom_point(mapping = aes(x = carat, y = price)) +
  theme_bw()
```

If we reduce the transparency (`alpha`), overplotting becomes less of a problem since we can see more clearly which pairs of carat and price are more common than others. We see that many pairs are concentrated along vertical lines, where carat is constant.
```{r}
ggplot(data = diamonds) + 
  geom_point(mapping = aes(x = carat, y = price), alpha = 1 / 100) +
  theme_bw()
```

## Lab 7 (Jesse)

### `Dates` in `R`

Dates and times are common types of data that are often tricky to deal with. 
Consider, for example, the number of days in a year, number of hours in a day, and the number of seconds in a minute.

* On leap years the number of days in a year changes.
* While normally 24, the number of hours in a day changes due to daylight savings. 
* The number of seconds in a minute even sometimes changes (leap seconds, which are rare events used to adjust for the slowing of earth's rotation)!

### Creating `Dates`

To create a date object in `R`, we could use a function to get improtant dates/times (e.g. `lubridate::today()`), we can try to build a `Date` from individual components (e.g. `lubridate::make_date(year = 2022, month = 2, day = 8)`), or we could *parse* a string into a date object. 

Here are some examples: 

```{r parseDates}
d1 <- "January 1, 2021"
d2 <- "11-21-1986"
d3 <- "01/24, '11 2:01 PM EST"

parse_date(d1, format = "%B %d, %Y")
parse_date(d2, format = "%m-%d-%Y")  
lubridate::mdy(d2)
parse_datetime(d3, format = "%m/%d, '%y %H:%M %p %Z")
```


### Working with `Dates`

When we have `Date` objects, we might want to perform some kind of arithmetic with these objects. 
This can be quite tricky, because the length of time between human friendly `Dates` isn't always consitent. 
For example, should the difference between Jan 1 2017 and Jan 1 2016 be one year (usually 365 days), or should it be 366 days (since 2016 was a leap year)? 
What if we want to time span in seconds? 

`lubridate` provides three classes to help deal with this issue: 

* `durations`: Total time span in seconds. There are some useful constructor functions that we can us, such as `dseconds()`, `dminutes()`, `dhours()`, etc. 
* `periods`: Human friendly time spans. For example, if you want to add a year to `"2016-01-01"`, adding a period of `years(1)` would add 366 days since 2016 is a leap year, and the output would be `"2017-01-01"`. The useful constructor functions for this includes `seconds()`, `minutes()`, `hours()`, etc. 
* `intervals`: These are used because periods are sometimes ambiguous (as noted above, `years(1)` could mean 366 or 365 days, depending on the year).

### Pivoting

We often work with data that are "tidy", meaning that each row corresponds to an observation, each column corresponds to a variable, and each cell has a single value. (See the picture below)

<center>

![Illustration of tidy data, from the R for Data Science book book](images/tidyData.png){width=100%}

</center>

A common problem is a dataset where some of the column names are not names of variables, but *values* of a variable. 
For example, let's consider the `table4a` dataset, which contains the number of Tuberculosis cases for 3 different countries: 

```{r table4aRaw}
table4a
```

Here we notice that there are two columns, `1999` and `2000`, that aren't variables but instead are values of a particular variable. 
We can fix this using the `pivot_longer` function. 

`pivot_longer`: this function "lengthens" data, increasing the number of rows and decreasing the number of columns.
For more detailed examples and exercises, I recommend looking at `vignette("pivot")`. For now, here are the most important arguments for this function: 

* `data`: The dataset we want to *pivot* longer.
* `cols`: The columns that need to be pivoted. This can be given as a vector of strings, or we could use any type of function we would select columns with using the `select` function. 
* `names_to`: The name of the column that will store the long variable names.  
* `values_to`: The name of the column that will store the values.

Here's what it would look like for the `table4a` dataset: 

```{r table4aPivot, exercise = TRUE}
table4a |>
  pivot_longer(
    cols = -country, # Get everything except first column,
    names_to = "year",
    values_to = "TB_count"
  ) |> 
  mutate(year = as.integer(year))
```

`pivot_longer` is often useful for plotting with `ggplot`, because it allows us to use colors and facets based on the created variables. 
For example, you could color `TB_count` by `year` now that we have made the data "longer". 

Sometimes we can see the opposite problem: a single observation is scattered across multiple rows. To fix this issue, we would use the `pivot_wider` function. 
This issue is not as common, so we won't go into much detail on this for now. 

*Pivoting* (both longer and wider) can be a tricky idea, and it can take some practice to fully understand how to use these really powerful functions correctly. 
For more resources, we strongly recommend looking at `vignette("pivot")`. 

## Lab 8 (Yilei)

### Duplicate Keys

#### One table has duplicate keys

This is useful when you want to add in additional information as there is typically a one-to-many relationship.

![](images/join-one-to-many.png){width=90%}

#### Both tables have duplicate keys

This represents a many-to-many join and is usually an error since the key does not uniquely identify observations in either table. Joining duplicated keys results in the Cartesian product of all the possible matches.

![](images/join-many-to-many.png){width=90%}


### Defining the Key Columns

When we do a join using left_join, R takes as the key whatever column names the two tables have in common.

A named character vector: `by = c(“a” = “b”)`. This will match variable a in table x to variable b in table y. The variables from x will be used in the output. For example, if we want to draw a map we need to combine the flights data with the airports data which contains the location (lat and lon) of each airport. Each flight has an origin and destination airport, so we need to specify which one we want to join to:

```{r}
flights2 <- flights %>% 
  select(year:day, hour, origin, dest, tailnum, carrier)

flights2 %>% 
  left_join(airports, c("dest" = "faa")) %>% head
```


### Filtering Joins

#### Semi-join
`semi_join(x, y)` keeps all the observations in `x` that are also in `y`.
![](images/join-semi.png){width=90%}

#### Anti-join

The opposite of a `semi-join` is an `anti-join`: keeps all the observations in `x` that are not in `y`.
![](images/join-anti.png){width=90%}

## Lab 9 (Benjamin)

## Lab 10 (Victor)

### Strings and String Functions

Recall that a **string** is a sequence of characters.

Below is an example of a string as it would appear on paper.
```
backyard
```

Strings in R work differently than they do on paper. In R, a string **must either begin and end with a double quote `"` or begin and end with a single quote `'`.**
```{r}
"backyard"
'backyard'
```

Certain characters are inserted in strings using **escape sequences**. An escape sequence starts with a backslash `\`. For example, the escape sequence for `tab` is `\t`. The backslash combines with the next character to form an escape sequence. See the help page on `Quotes` for the list of valid escape sequences in R. This is how a tab would be inserted in the previous string.
```{r}
"back\tyard"
```

```{r, echo = TRUE}
line1 <- "Nor shall death brag thou wander'st in his shade,"
line2 <- "When in eternal lines to time thou grow'st:"
line3 <- "So long as men can breathe or eyes can see,"
line4 <- "So long lives this, and this gives life to thee."
sonnet18_end <- c(line1, line2, line3, line4)
```

#### `str_length()`

To find the length of the strings in terms of characters:
```{r}
str_length(sonnet18_end) # base::nchar also works
```

#### `str_sub()`

The `str_sub` function can retrieve or change **substrings**.

```{r}
str_sub(line1, 11, 20)
str_sub(line2, 36)
str_sub(line2, -8)
line4b <- line4
str_sub(line4b, 1, 10) <- "REMOVED"
line4b
```

#### `str_c()`

If we need to make strings out of other strings, we have two (more or less identical) functions:

* Old school: `paste` (joins with " ") and `paste0` (joins with "")
* New school: `str_c` (joins with ""); used in our book

```{r}
str_c("Section", c("100", "200", "300"), 
      "meets on", 
      c("Monday", "Tuesday", "Wednesday"),
      sep = " ")
```
Notice: this is a vector of length 3, use `collapse = "SEP"` to make a single string from a vector.
```{r}
str_c("Section", c("100", "200", "300"), 
      "meets on", 
      c("Monday", "Tuesday", "Wednesday"),
      sep = " ",
      collapse = ", ")
```

#### `str_split()`

Here's the full sonnet as a single string:
```{r}
sonnet18 <- "Shall I compare thee to a summer's day?\nThou art more lovely and more temperate:\nRough winds do shake the darling buds of May,\nAnd summer's lease hath all too short a date;\nSometime too hot the eye of heaven shines,\nAnd often is his gold complexion dimm'd;\nAnd every fair from fair sometime declines,\nBy chance or nature's changing course untrimm'd;\nBut thy eternal summer shall not fade,\nNor lose possession of that fair thou ow'st;\nNor shall death brag thou wander'st in his shade,\nWhen in eternal lines to time thou grow'st:\n\tSo long as men can breathe or eyes can see,\n\tSo long lives this, and this gives life to thee."
```

Let's split that up into individual lines as strings in a vector:
```{r}
sonnet18_lines <- str_split(sonnet18, "\n") # notice use of new line
sonnet18_lines
```

What is happening? Since `sonnet18` could have had multiple entries (vector), `str_split` returns a **list** with splits for each item in the vector:
```{r}
str_split(c("a b c", "d e"), " ")
```

In this case:
```{r}
sonnet18_lines <- sonnet18_lines[[1]] # [[]] for lists
```

### Regular Expressions

A **regular expression** is a string specifying a pattern that other strings may or may not match. Regular expressions can be used to

  - find strings matching a pattern
  - modify substrings matching a pattern
  - delete substrings matching a pattern

#### Metacharacters

Several characters have special meanings inside regular expressions. They are called **metacharacters**. These are the metacharacters:

`. \ | ( ) [ ] ^ $ { } * + ?`

For example, `.` matches any character.

If you do not want a metacharacter to have its special meaning, you need to prepend it with **two** backslashes.
```{r}
str_view_all(c("$2.50", "2 dollars"), "\\.")
```

#### Character Classes

- `.` matches any character
- `[abcd]` matches any one of the characters between the brackets
- `[^abcd]` matches any character *not* between the brackets (excluding `^`)
- `[a-d]` matches any character in the specified range; it's the same as `[abcd]`

An example:
```{r}
str_view_all(c("$2.50", "2 dollars"), "[a-zA-Z]")
```

#### Shorthand

- `\w` matches a "word" character, equivalent to `[0-9A-Za-z_]`, i.e., digits, letters, and the underscore
- `\s` matches any whitespace character, including tabs and newlines
- `\d` matches digits, equivalent to `[0-9]`
- `\W`, `\S`, and `\D` match the opposite of the lower-case versions

In the example below, we check which string contains whitespace. Note that **two** backslashes need to be used.
```{r}
str_view_all(c("$2.50", "2 dollars"), "\\s")
```

#### Grouping

- `()` are used to group patterns together. This can be used to extract matches individually.
- `\1` refers to the match to the first group, `\2` refers to the match to the second group, etc.

In this example, we check which string contains a repeated letter.
```{r}
str_view_all(c("$2.50", "2 dollars"), "([a-z])\\1")
```

#### Operators

- `|` is the OR operator and allows matches of either side
- `{}` describes how many times the preceeding character or group must occur:
  - `{m}` must occur exactly `m` times
  - `{m,n}` must occur between `m` and `n` times, inclusive
  - `{m,}` Must occur at least `m` times
- `*` means the preceeding character can appear zero or more times, equivalent to `{0,}`
- `+` means the preceeding character must appear one or more times, equivalent to `{1,}`
- `?` means the preceeding character can appear zero or one time, equivalent to `{0,1}`

Which string has two digits in a row?
```{r}
str_view_all(c("$2.50", "2 dollars"), "[0-9]{2}")
```

#### Anchors

- `^` matches the start of a string (or line)
- `$` matches the end of a string (or line)
- `\b` matches a word boundary
- `\B` matches not word boundary

Which string starts with a dollar sign? Note that `$` is escaped with **two** backslashes.
```{r}
str_view_all(c("$2.50", "2 dollars"), "^\\$")
```

## Lab 11 (Benjamin)
### Iteration
- We learned that looping is a useful tool for reducing duplication.
- We looked at three major forms of iteration
- **For Loops**, **While Loops** and the **Map family**
- Let's briefly review of of these

### For Loops
- For loops are particularly useful when you have an idea of the number of steps until a process terminates
- The syntax is given by:
```
    for (index in vector) {
       [do something for each index]
    }
```
- While this is a generic syntax, there are three major forms in which for loops may be used:      

- **(1) Looping along the indices of a vector**           
```{r}
## Let's first look at how indices of a vector appear
for(i in 1:5) {
       print(i)
}
```


- **(2) Looping along the elements of a vector**   
```{r}
x <- c("a", "b", "c", "d")

for(i in x) {
     ## Print out each element of 'x'
     print(i)
} 
```


- **(3) Looping along the length a vector **   
```{r}
## Generate a sequence based on length of 'x'
for(i in seq_along(x)) {   
         print(x[i])
}
```

### While Loops
- This is particularly helpful when we do not know how many steps until a process terminates
- The syntax is given by:
```
     <OPTIONALLY INITIALIZING THE ITERATOR>
     while (<condition is true>) {
        [do something]

        <OPTIONALLY INCREMENTING THE ITERATOR>
     }
```

- **Example:**     
Divide (scale) all numeric columns in `Iris` dataset by 20
```{r}
## Before Loop
head(iris)
```

```{r}
col_iter <- 1
while(is.numeric(iris[, col_iter])){
  iris[, col_iter] <- iris[, col_iter] /10
  col_iter <- col_iter + 1
}
```

```{r}
## After Loop
head(iris)
```

### The Map Family
- As we saw in the previous examples, looping can sometimes take up storage and may require initializing a vector.    
- A simpler and perhaps more desirable alternative is using the `map[_*]()` family of functions from the `purrr` package  
- Map can be used for iterating over a **single** or **multiple** vectors concurrently.

### **1. map (for a single input)**
![](images/map1.png){width=90%}

- **Example:**
We wish to take the length of every element of the parent list: 

```{r}
moons <-
  list(
    earth = 1737.1,
    mars = c(11.3, 6.2),
    neptune = 
      c(60.4, 81.4, 156, 174.8, 194, 34.8, 420, 2705.2, 340, 62, 44, 42, 40, 60)
  )
```

Using `map` this is evaluated as:

![](images/map2.png){width=90%}


### **2. map2 (for two inputs)**
![](images/map5.png){width=90%}

**Example**  

- Find each student's best performing score for each subject as a new column
```{r}
df <-
  tibble(
  Student = c("John", "Dan", "Nancy"),
  English = c(50, 90, 70),
  Math    = c(100, 65, 88)
  )

df %>% 
  mutate(`Max score` = map2_dbl(English, Math, max))
```


### **3. pmap (for multiple inputs)** 
![](images/map6.png){width=90%}

**Example** 
Find the row-wise minimum as a new column in the dataframe below
```{r}
tibble(
  a = c(50, 60, 70),
  b = c(10, 90, 40),
  c = c(1, 105, 2000)
) %>% 
  pmap_dbl(min)

```



### Output variants
- The default `map[_*]()` family of functions return a `list` as the output.  
- However, we may want atomic vectors (***integers, doubles, characters, logical***) to be the outputs for specific tasks.
- Below gives variations of the `map` functional together with descriptions:


- `map_int()`, `map2_int()`, `pmap_int()` creates an integer vector.
- `map_dbl()`, `map2_dbl()`, `pmap_dbl()` creates a double vector.
- `map_chr()`, `map2_chr()`, `pmap_chr()` creates a character vector.
- `map_lgl()`, `map2_lgl()`, `pmap_lgl()` creates a logical vector.
- `map_df()` creates a dataframe.




## Lab 12 (Jesse)

### Parallelization in `R` 

Sometimes our code doesn't need to run sequentially, i.e., we could do all of our computations at the same time. 
This is often true when we write code that works with the family of functions like `map` and `apply` (this is also true of some `for`-loops).

When this is the case, we might be able to speed up our code by running *cores* on our computer. 
A core works essentially like the brain of a computer: it takes a set of instructions, performs those instructions, and returns a result. 
Almost all computers these days have multiple cores, meaning we could send a set of multiple different instructions to our computer at the same time! 
This is called *parallelization*. 

There are a few ways to parallelize in `R`, but we are just focusing on parallelization with *Socket Clusters*.

To do this, we should first check how many cores our computer can use with the command: 

```{r getCores}
numCores <- detectCores()
numCores
```

Now, we create a *Socket Cluster*.
When we make a Socket Cluster, we are starting new `R` processes on our computer, so this means that packages and variables that were created outside of the cluster will not be available to us. 

```{r makeCluster}
cl <- makeCluster(numCores)
```

Let's now create a large matrix of random numbers. 
Each column of the matrix will be 5,000 iid observations from a $N(i, \sqrt{i})$ distribution, for $i \in 1:400$ (variance equal to $i$).

```{r MakeRandomMatrix}
Rmatrix <- sapply(1:400, function(x) rnorm(1000, mean = x, sd = sqrt(x)))
remove_missing <- TRUE

mean_narm <- function(x) {
  mean(x, na.rm = remove_missing)
}
```

Now let's take the mean of each column of the matrix: 

```{r parallelError, error=TRUE, message=TRUE, eval=TRUE, warning=TRUE}
means <- parApply(cl, Rmatrix, 2, mean_narm)
```
Notice that this results in an error! We need to *export* the variable "remove_missing" to the cluster! 

```{r parallelCorrect, message=TRUE, eval=TRUE,warning=TRUE}
clusterExport(cl, "remove_missing")
means <- parApply(cl, Rmatrix, 2, mean_narm)

stopCluster(cl)
plot(1:400, 1:400 - means, xlab = "Column Number (mean / var)", ylab = "mean - estimated mean")
```

### Debugging Tools

This is a large topic! For more resources, consider reading the chapter on debugging in the [Advanced R textbook](https://adv-r.hadley.nz/debugging.html). 
Here we will just briefly mention some useful debugging tools. 

- `traceback()`: If you're using `R` Studio, then you'll get a message when you get an error with a `Show Traceback` option. This is equivalent to running the function `traceback()`, but formatted nicely. This function will show you which functions where run and in what order, which is helpful for locating bugs inside of nested functions. 
- `browser()`: If you would like interactive debugger, you can place `browser()` statements in your `R` code, and when you run your code, this will pause everything at each `browser()` step, allowing you to look at the state of the `R` *environment* at each step. Rstudio also has a similar functionality called *Breakpoints* that can be activated by clicking to the left of the line number that you would like to pause on. This is called 

### Performance Evaluation Tools

- Profiling: profiling helps us determine which part of our code/function is the slowest, or what parts of the code are using most of the computing time (i.e., a function might be really fast, but if it's used thousands of times then the profiler will show that the function is a *bottleneck*) and also gives a rough estimate of how long each part the code/function takes. The best way to do this is the `profvis` package in `R`. In `RStudio`, there is a drop-down menu called *Profile* that does this for you.  
- (Micro)Benchmarking: Benchmarking provides a much more accurate estimate of how long a part of the code takes by running the same piece of code many times and providing summary statistics of the resulting computing time. This also let's us compare the speed of several functions, which can help us decide how to implement a particular algorithm. One easy way of doing this is the `bench` package: `bench::mark(f1(), f2(), f3(), ...)`: 

```{r benchmarkExample}
x <- runif(100)
(lb <- bench::mark(
  sqrt(x),
  x ^ 0.5
))

plot(lb)
```
like the figure above, microbenchmark times tend to be heavily right-skewed, so it's better to compare computing speeds using median times rather than mean times. 

## Lab 13 (Yilei)

### Shiny Framework

Every Shiny app has two key components: the UI (short for user interface) which defines how your app looks, and the server function which defines how your app works. Shiny uses reactive programming to automatically update outputs when inputs change, so we’ll need the third important component of Shiny apps: reactive expressions.

A simple example:

```{r, eval=FALSE, echo=TRUE}
ui <- fluidPage(
  selectInput("dataset", label = "Dataset", choices = ls("package:datasets")),
  verbatimTextOutput("summary"),
  tableOutput("table")
)

server <- function(input, output, session) {
  output$summary <- renderPrint({  # "summary" is the output ID we used for verbatimTextOutput() in ui control
    dataset <- get(input$dataset, "package:datasets") # retrieve dataset from the list package::datasets
    summary(dataset)  # Output the summary of the dataset
  })
  
  output$table <- renderTable({ # "table" is the output ID we used for tableOutput() in ui control
    dataset <- get(input$dataset, "package:datasets")
    dataset # Output the dataset
  })
}

shinyApp(ui, server)
```

The `ui` part has four functions:

* `fluidPage()` is a layout function that sets up the basic visual structure of the page.

* `selectInput()` is an input control that lets the user interact with the app by providing a value. In this case, it’s a select box with the label “Dataset” and lets you choose one of the built-in datasets that come with R.

* `verbatimTextOutput()` and `tableOutput()` are output controls that tell Shiny where to put rendered output (we’ll get into the how in a moment). `verbatimTextOutput()` displays code and `tableOutput()` displays tables.

The `server` part is defined in the following way:

* The left-hand side of the assignment operator (`<-`), `output$ID`, indicates that you’re providing the recipe for the Shiny output with that ID. 

* The right-hand side of the assignment uses a specific render function to wrap some code that you provide. Each `render{Type}` function is designed to produce a particular type of output (e.g. text, tables, and plots), and is often paired with a `{type}Output` function in UI control. For example, in this app, `renderPrint()` is paired with `verbatimTextOutput()` to display a statistical summary with fixed-width (verbatim) text, and `renderTable()` is paired with `tableOutput()` to show the input data in a table.


Run the app again and play around, watching what happens to the output when you change an input. The following figure shows what you should see when you open the app.

![](images/server.png){width=80%}

### Reactive Expressions

Even in this simple example, we have some code that’s duplicated: the following line is present in both outputs.

```{r, eval=F, echo=T}
dataset <- get(input$dataset, "package:datasets")
```

To reduce the repetition here, we can create a reactive expression by wrapping a block of code in `reactive({...})` and assigning it to a variable, and you use a reactive expression by calling it like a function. But while it looks like you’re calling a function, a reactive expression has an important difference: it only runs the first time it is called and then it caches its result until it needs to be updated.

We can update our `server()` to use reactive expressions, as shown below. The app behaves identically, but works a little more efficiently because it only needs to retrieve the dataset once, not twice.

```{r, eval=F, echo=T}

server <- function(input, output, session) {
  # Create a reactive expression
  dataset <- reactive({
    get(input$dataset, "package:datasets")
  })

  output$summary <- renderPrint({
    # Use a reactive expression by calling it like a function
    summary(dataset())
  })
  
  output$table <- renderTable({
    dataset()
  })
}
```



